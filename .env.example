# MRIA Environment Variables Configuration Template
# Copy this file to .env and fill in your actual values

# ===== API Keys =====
# OpenAI API Key for GPT models
OPENAI_API_KEY=your_openai_api_key_here

# Alternative environment variable name (used in your current code)
OPEN_API_KEY=your_openai_api_key_here

# Google Gemini API Key
GEMINI_API_KEY=your_gemini_api_key_here

# ===== LangSmith Configuration =====
# LangSmith API Key for tracing and monitoring
LANGCHAIN_API_KEY=your_langsmith_api_key_here

# LangSmith Project Name (optional)
LANGCHAIN_PROJECT=MRIA-Development

# Enable LangSmith tracing (true/false)
LANGCHAIN_TRACING_V2=true

# ===== Google Cloud Platform =====
# Path to your Google Cloud Service Account JSON file
GOOGLE_APPLICATION_CREDENTIALS=/path/to/your/service-account-key.json

# ===== Database Configuration =====
# PostgreSQL connection string for memory storage
POSTGRES_CONNECTION_STRING=postgresql://username:password@host:port/database

# ===== Vector Database (Qdrant) =====
# Qdrant cluster URL
QDRANT_URL=https://your-qdrant-cluster-url

# Qdrant API Key
QDRANT_API_KEY=your_qdrant_api_key

# Qdrant collection name
QDRANT_COLLECTION_NAME=MRIA_collection

# ===== Application Configuration =====
# Default user ID for testing
DEFAULT_USER_ID=1

# Default thread ID for testing
DEFAULT_THREAD_ID=1

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# ===== Model Configuration =====
# Hugging Face model name for ColQwen2
MODEL_NAME=vidore/colqwen2-v0.1

# Device for model inference (cpu, cuda, mps)
MODEL_DEVICE=cpu

# ===== Search Configuration =====
# Maximum number of search results to return
SEARCH_LIMIT=20

# Number of results to prefetch before reranking
PREFETCH_LIMIT=200